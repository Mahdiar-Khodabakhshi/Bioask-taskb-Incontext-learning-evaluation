{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "715dba73fa0c465fabb98e66f1bfb2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0da320e310dd44998b6655cc6e122bfc",
              "IPY_MODEL_2a42f9bca5c44af199691d6d22dce1d6",
              "IPY_MODEL_626fc6424068464fbec0761600618f8b"
            ],
            "layout": "IPY_MODEL_60e94a5b925c4047903df35913ad22db"
          }
        },
        "0da320e310dd44998b6655cc6e122bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08d35147d39a4915840ccfa81b8dd50a",
            "placeholder": "​",
            "style": "IPY_MODEL_9f43490a0a8944c6b014c86aa82f3992",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2a42f9bca5c44af199691d6d22dce1d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66c36c2ce7404dda943e8643869adf12",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0fbb4299bf914093a54e6dfe7720697a",
            "value": 2
          }
        },
        "626fc6424068464fbec0761600618f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6908b2a695954b2288c3f8159a976673",
            "placeholder": "​",
            "style": "IPY_MODEL_f64612b35f554777be82628946023538",
            "value": " 2/2 [00:55&lt;00:00, 24.86s/it]"
          }
        },
        "60e94a5b925c4047903df35913ad22db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d35147d39a4915840ccfa81b8dd50a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f43490a0a8944c6b014c86aa82f3992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66c36c2ce7404dda943e8643869adf12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fbb4299bf914093a54e6dfe7720697a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6908b2a695954b2288c3f8159a976673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f64612b35f554777be82628946023538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850,
          "referenced_widgets": [
            "715dba73fa0c465fabb98e66f1bfb2fa",
            "0da320e310dd44998b6655cc6e122bfc",
            "2a42f9bca5c44af199691d6d22dce1d6",
            "626fc6424068464fbec0761600618f8b",
            "60e94a5b925c4047903df35913ad22db",
            "08d35147d39a4915840ccfa81b8dd50a",
            "9f43490a0a8944c6b014c86aa82f3992",
            "66c36c2ce7404dda943e8643869adf12",
            "0fbb4299bf914093a54e6dfe7720697a",
            "6908b2a695954b2288c3f8159a976673",
            "f64612b35f554777be82628946023538"
          ]
        },
        "id": "VKUDiJ1M6TOF",
        "outputId": "56b76d56-7a72-4533-c0e7-a2cb40156b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "715dba73fa0c465fabb98e66f1bfb2fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device device because they were offloaded to the cpu.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact Answer: ['programmed death-1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact Answer: ['FECH gene, ferrochelatase']\n",
            "Exact Answer: [\"3' flanking region\"]\n",
            "Exact Answer: ['SNP2TFBS']\n",
            "Exact Answer: ['Phosphonormalizer']\n",
            "Exact Answer: ['Coronavirus']\n",
            "Exact Answer: ['lack of H1']\n",
            "Exact Answer: ['apoptosis']\n",
            "Exact Answer: ['CD19']\n",
            "Exact Answer: ['Stata']\n",
            "Exact Answer: ['>200 nucleotides']\n",
            "Exact Answer: ['prominent small vessels']\n",
            "Exact Answer: ['Chromosome 15']\n",
            "Exact Answer: ['This protein functions as an Na-K-Cl cotransporter.']\n",
            "Exact Answer: ['transdermal drug-coated microneedle patch system']\n",
            "Exact Answer: ['Osteoporosis']\n",
            "Exact Answer: [\"Classic Bartter's syndrome has been demonstrated to result from defective chloride transport across the basolateral membrane in the distal nephron due to mutations in the chloride channel gene CLCNKB.\"]\n",
            "Exact Answer: ['Metabolite annotation by database searching in mass spectrometry-based metabolomics']\n",
            "Exact Answer: ['senktide']\n",
            "Exact Answer: ['angiotensin II receptor']\n",
            "Exact Answer: ['immune cells']\n",
            "Exact Answer: ['DeepCpG']\n",
            "Exact Answer: ['10 June 2016']\n",
            "Exact Answer: ['Leuprorelin acetate']\n",
            "Exact Answer: ['Astellas Pharma GmbH']\n",
            "Exact Answer: ['Edit-distance']\n",
            "Exact Answer: ['20']\n",
            "Exact Answer: ['MannKind Corporation']\n",
            "Exact Answer: ['DeepSynergy']\n",
            "Exact Answer: ['easyGWAS']\n",
            "Exact Answer: ['Microinjection system for intradermal vaccine delivery']\n",
            "Exact Answer: ['320kbp']\n",
            "All generated answers have been saved to /content/generated_8B5.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# Load the JSON file\n",
        "file_path = \"/content/extracted_8B5_golden.json\"\n",
        "with open(file_path, \"r\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Initialize the model and tokenizer\n",
        "model_id = \"nvidia/Llama3-ChatQA-1.5-8B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "\n",
        "def get_formatted_input(messages, context):\n",
        "    system = \"System: This is a chat between a user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions based on the context. The assistant should also indicate when the answer cannot be found in the context.\"\n",
        "    instruction = \"Answer this question by returning only a JSON string array of entity names, numbers, or similar short expressions that are an answer to the question, ordered by decreasing confidence. The array should contain at max 5 elements but can contain less. If you don't know any answer return an empty list. Return only this list, it must not contain phrases and **must be valid JSON**.\"\n",
        "\n",
        "    for item in messages:\n",
        "        if item['role'] == \"user\":\n",
        "            ## only apply this instruction for the first user turn\n",
        "            item['content'] = instruction + \" \" + item['content']\n",
        "            break\n",
        "\n",
        "    conversation = '\\n\\n'.join([\"User: \" + item[\"content\"] if item[\"role\"] == \"user\" else \"Assistant: \" + item[\"content\"] for item in messages]) + \"\\n\\nAssistant:\"\n",
        "    formatted_input = system + \"\\n\\n\" + context + \"\\n\\n\" + conversation\n",
        "\n",
        "    return formatted_input\n",
        "\n",
        "# Initialize a list to store generated answers\n",
        "generated_answers_list = []\n",
        "\n",
        "# Iterate through the dataset\n",
        "for entry in data:\n",
        "    question = entry['body']\n",
        "    context = \"\\n\".join(entry['snippets'])\n",
        "    exact_answer = entry['exact_answer']\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        "\n",
        "    formatted_input = get_formatted_input(messages, context)\n",
        "    tokenized_prompt = tokenizer(tokenizer.bos_token + formatted_input, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # Set pad_token_id to eos_token_id to avoid warning\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    # Generate the response with temperature set to 0 and do_sample set to False\n",
        "    outputs = model.generate(\n",
        "        input_ids=tokenized_prompt.input_ids,\n",
        "        attention_mask=tokenized_prompt.attention_mask,\n",
        "        max_new_tokens=128,\n",
        "        pad_token_id=pad_token_id,\n",
        "        temperature=0.0,  # Set temperature to 0\n",
        "        do_sample=False  # Ensure deterministic output\n",
        "    )\n",
        "\n",
        "    response = outputs[0][tokenized_prompt.input_ids.shape[-1]:]\n",
        "    generated_answer = tokenizer.decode(response, skip_special_tokens=True).strip()\n",
        "\n",
        "    # Store the generated answer in the list\n",
        "    generated_answers_list.append({\n",
        "        \"question\": question,\n",
        "        \"exact_answer\": exact_answer,\n",
        "        \"generated_answer\": generated_answer\n",
        "    })\n",
        "\n",
        "    print(f\"Exact Answer: {exact_answer}\")\n",
        "    # print(f\"Generated Answer: {generated_answer}\")\n",
        "\n",
        "# Save all generated answers to a JSON file\n",
        "output_file_path = \"/content/generated_8B5.json\"\n",
        "with open(output_file_path, \"w\") as outfile:\n",
        "    json.dump(generated_answers_list, outfile, indent=4)\n",
        "\n",
        "print(f\"All generated answers have been saved to {output_file_path}\")"
      ]
    }
  ]
}